{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45fd07c",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition with FastAI\n",
    "\n",
    "This notebook demonstrates how to fine-tune a machine learning model using the MNIST dataset with FastAI for handwritten digit recognition. The model will be trained to classify handwritten digits (0-9) and then saved for future use.\n",
    "\n",
    "## Overview\n",
    "- Load and explore the MNIST dataset\n",
    "- Prepare data loaders with augmentations\n",
    "- Create a CNN model using FastAI's vision learner\n",
    "- Train and fine-tune the model\n",
    "- Evaluate performance\n",
    "- Save the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945259a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Let's start by importing all the necessary libraries for our handwritten digit recognition project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70955f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.external import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set up matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Device setup - simplified approach for maximum compatibility\n",
    "print(\"Configuring device...\")\n",
    "\n",
    "# Check for CUDA (NVIDIA GPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"‚úÖ CUDA GPU detected: {device_name}\")\n",
    "    print(f\"üìä GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"üîß Using device: {device}\")\n",
    "\n",
    "    # Set CUDA optimizations\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.set_default_device(device)\n",
    "\n",
    "# Check for MPS (Apple Silicon GPU) - use CPU for training, MPS for inference\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    print(\"‚úÖ Apple Metal Performance Shaders (MPS) detected\")\n",
    "    print(\"‚ö†Ô∏è  Note: MPS has compatibility issues with FastAI training\")\n",
    "    print(\"üîß Using CPU for training, MPS for inference\")\n",
    "\n",
    "    # Use CPU for training due to FastAI compatibility issues\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"üîß Training device: {device}\")\n",
    "\n",
    "    # Set default device to CPU for training\n",
    "    torch.set_default_device(device)\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    print(\"üí° After training, models can be moved to MPS for faster inference\")\n",
    "\n",
    "# Fallback to CPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, using CPU\")\n",
    "    print(f\"üîß Using device: {device}\")\n",
    "    torch.set_default_device(device)\n",
    "\n",
    "print(f\"üß† PyTorch version: {torch.__version__}\")\n",
    "print()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea420d7",
   "metadata": {},
   "source": [
    "## 2. Load and Explore MNIST Dataset\n",
    "\n",
    "The MNIST dataset contains 70,000 grayscale images of handwritten digits (0-9), each 28x28 pixels. We'll use FastAI's built-in functionality to download and load this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load MNIST dataset\n",
    "print(\"Downloading MNIST dataset...\")\n",
    "path = untar_data(URLs.MNIST)\n",
    "print(f\"Dataset downloaded to: {path}\")\n",
    "\n",
    "# Explore the dataset structure\n",
    "print(\"\\nDataset structure:\")\n",
    "print(f\"Path contents: {list(path.ls())}\")\n",
    "\n",
    "# Check training and testing folders\n",
    "train_path = path / \"training\"\n",
    "test_path = path / \"testing\"\n",
    "\n",
    "print(f\"\\nTraining classes: {[f.name for f in train_path.ls().sorted()]}\")\n",
    "print(f\"Testing classes: {[f.name for f in test_path.ls().sorted()]}\")\n",
    "\n",
    "# Count images in each class\n",
    "print(\"\\nNumber of training images per class:\")\n",
    "for class_folder in train_path.ls().sorted():\n",
    "    count = len(list(class_folder.ls()))\n",
    "    print(f\"Class {class_folder.name}: {count} images\")\n",
    "\n",
    "print(\"\\nNumber of testing images per class:\")\n",
    "for class_folder in test_path.ls().sorted():\n",
    "    count = len(list(class_folder.ls()))\n",
    "    print(f\"Class {class_folder.name}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092528b2",
   "metadata": {},
   "source": [
    "## 3. Prepare Data Loaders\n",
    "\n",
    "We'll create data loaders with appropriate transformations and augmentations to improve model performance and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders with transformations\n",
    "dls = ImageDataLoaders.from_folder(\n",
    "    path,\n",
    "    train=\"training\",\n",
    "    valid=\"testing\",\n",
    "    item_tfms=Resize(28),  # Ensure all images are 28x28\n",
    "    batch_tfms=[\n",
    "        *aug_transforms(size=28, min_scale=0.8, max_rotate=10.0, max_lighting=0.2),\n",
    "        Normalize.from_stats(*imagenet_stats)\n",
    "    ],\n",
    "    bs=64,  # batch size\n",
    "    device=device,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(dls.train_ds)}\")\n",
    "print(f\"Validation samples: {len(dls.valid_ds)}\")\n",
    "print(f\"Classes: {dls.vocab}\")\n",
    "print(f\"Number of classes: {dls.c}\")\n",
    "\n",
    "if device:\n",
    "    print(f\"üîß Data loaders configured for device: {device}\")\n",
    "\n",
    "# Display sample images from the dataset\n",
    "print(\"\\nSample training images:\")\n",
    "dls.show_batch(max_n=12, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eca555",
   "metadata": {},
   "source": [
    "## 4. Create the Model Architecture\n",
    "\n",
    "We'll use a pre-trained ResNet18 model and fine-tune it for our digit classification task. FastAI makes this process very straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0eafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN learner with ResNet18 architecture\n",
    "learn = vision_learner(\n",
    "    dls,\n",
    "    resnet18,\n",
    "    metrics=[accuracy, error_rate],\n",
    "    loss_func=CrossEntropyLossFlat()\n",
    ")\n",
    "\n",
    "print(\"Model created successfully!\")\n",
    "print(f\"Model architecture: {learn.model.__class__.__name__}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in learn.model.parameters()):,}\")\n",
    "\n",
    "# Handle device-specific configurations\n",
    "if device:\n",
    "    print(f\"üîß Model will use device: {device}\")\n",
    "\n",
    "    # Show GPU memory usage if CUDA\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"üíæ GPU Memory allocated: {torch.cuda.memory_allocated(device) / 1024**2:.1f} MB\")\n",
    "        print(f\"üíæ GPU Memory cached: {torch.cuda.memory_reserved(device) / 1024**2:.1f} MB\")\n",
    "\n",
    "# Display model summary\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860696a0",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "We'll use FastAI's learning rate finder and one-cycle training policy to efficiently train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal learning rate\n",
    "print(\"Finding optimal learning rate...\")\n",
    "lr_find_result = learn.lr_find()\n",
    "print(f\"Suggested learning rate: {lr_find_result.valley}\")\n",
    "\n",
    "# Plot learning rate finder results\n",
    "learn.recorder.plot_lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bfb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with simplified approach\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "print(f\"Training model for {epochs} epochs...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Use fine_tune for all devices (CUDA/CPU)\n",
    "    print(\"\ude80 Starting training...\")\n",
    "    learn.fine_tune(epochs, base_lr=learning_rate)\n",
    "\n",
    "except Exception as e:\n",
    "    # Print stack trace for debugging errors\n",
    "    import traceback\n",
    "    print(\"‚ö†Ô∏è  Exception occurred during training:\")\n",
    "    traceback.print_exc()\n",
    "    raise e\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# For Apple Silicon users: Move model to MPS for faster inference\n",
    "def get_inference_device():\n",
    "    \"\"\"Get the best device for inference\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# Move model to best inference device\n",
    "inference_device = get_inference_device()\n",
    "if inference_device != device:\n",
    "    print(f\"üîß Moving model to {inference_device} for faster inference...\")\n",
    "    learn.model = learn.model.to(inference_device)\n",
    "    print(f\"‚úÖ Model moved to {inference_device} for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b1d9b",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance\n",
    "\n",
    "Let's assess our model's performance using various metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation metrics\n",
    "valid_loss, accuracy = learn.validate()\n",
    "print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Final Validation Loss: {valid_loss:.4f}\")\n",
    "\n",
    "# Create classification interpretation\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "# Show confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "interp.plot_confusion_matrix(figsize=(10, 10))\n",
    "plt.title(\"MNIST Digit Recognition - Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Show most confused classes\n",
    "print(\"\\nMost confused pairs:\")\n",
    "confused_pairs = interp.most_confused(min_val=2)\n",
    "for pair in confused_pairs:\n",
    "    print(f\"Confused {pair[0]} with {pair[1]}: {pair[2]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show worst predictions (top losses)\n",
    "print(\"Analyzing worst predictions...\")\n",
    "interp.plot_top_losses(9, nrows=3, figsize=(12, 8))\n",
    "plt.suptitle(\"MNIST Digit Recognition - Worst Predictions\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Get predictions for classification report\n",
    "preds, targets = learn.get_preds()\n",
    "y_pred = torch.argmax(preds, dim=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(targets, y_pred, target_names=[str(i) for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f9a2f",
   "metadata": {},
   "source": [
    "## 7. Save the Trained Model\n",
    "\n",
    "Now let's save our trained model for future use and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60372461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the complete learner using FastAI's export method\n",
    "model_name = \"mnist_digit_recognizer\"\n",
    "model_path = models_dir / f\"{model_name}.pkl\"\n",
    "\n",
    "print(f\"Saving model to: {model_path}\")\n",
    "learn.export(model_path)\n",
    "\n",
    "# Also save just the model state dict for PyTorch compatibility\n",
    "torch_model_path = models_dir / f\"{model_name}_state_dict.pth\"\n",
    "torch.save(learn.model.state_dict(), torch_model_path)\n",
    "\n",
    "print(f\"‚úÖ FastAI model saved to: {model_path}\")\n",
    "print(f\"‚úÖ PyTorch state dict saved to: {torch_model_path}\")\n",
    "\n",
    "# Verify the saved model by loading it\n",
    "print(\"\\nVerifying saved model...\")\n",
    "loaded_learn = load_learner(model_path)\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffdc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved model with some sample predictions\n",
    "print(\"Testing model predictions on sample data...\")\n",
    "\n",
    "# Get a batch of validation data\n",
    "x, y = dls.valid.one_batch()\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "with torch.no_grad():\n",
    "    preds = loaded_learn.model(x)\n",
    "    pred_classes = torch.argmax(preds, dim=1)\n",
    "\n",
    "# Visualize some predictions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(8):\n",
    "    img = x[i].cpu()\n",
    "    # Denormalize the image for display\n",
    "    img = img * torch.tensor(imagenet_stats[1]).view(3, 1, 1) + torch.tensor(imagenet_stats[0]).view(3, 1, 1)\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "\n",
    "    # Convert to grayscale for display\n",
    "    if img.shape[0] == 3:\n",
    "        img = img.mean(dim=0)\n",
    "\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    correct = \"‚úÖ\" if y[i] == pred_classes[i] else \"‚ùå\"\n",
    "    axes[i].set_title(f\"True: {y[i]}, Pred: {pred_classes[i]} {correct}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Sample Predictions from Saved Model\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéâ MNIST digit recognition model training completed successfully!\")\n",
    "print(f\"üìä Final accuracy: {accuracy:.4f}\")\n",
    "print(f\"üíæ Model saved and ready for use!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
